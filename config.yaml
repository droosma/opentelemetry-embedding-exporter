receivers:
  otlp:
    protocols:
      http:
      grpc:

processors:
  batch:
  
exporters:
  embeddingexporter:
    verbosity: detailed
    embedding:
      key: ${env:OpenAIEmbeddingKey}
      endpoint: "https://rg-openai-sandbox.openai.azure.com/"
      model_id: "embedding"
    persistence:
      host     : "host.docker.internal"
      port     : "6379"
      password : ""
    publisher:
      enabled: true
      connection_string: ${env:AzureEventHubConnectionString}
  logging:
    verbosity: detailed

service:
  pipelines:
    # traces:
    #   receivers: [otlp]
    #   processors: [batch]
    #   exporters: [embeddingexporter]
    # metrics:
    #   receivers: [otlp]
    #   processors: [batch]
    #   exporters: [embeddingexporter]
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: 
        - embeddingexporter
        #- logging